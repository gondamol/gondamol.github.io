[
  {
    "objectID": "tidy-tuesday/index.html",
    "href": "tidy-tuesday/index.html",
    "title": "Tidy Tuesday Analysis",
    "section": "",
    "text": "Welcome to my Tidy Tuesday analysis collection! Each week, I participate in the Tidy Tuesday challenge, where I analyze different datasets and share my findings. Below are some of the projects I’ve worked on.\n\n\n\n2024-01-02: Analysis on Global Temperature Changes\n2024-01-09: Analysis on Movie Ratings Trends\n2024-01-16: Analysis on World Population Growth\n\nFeel free to explore each analysis to see the data visualization, statistical methods, and insights drawn from each dataset."
  },
  {
    "objectID": "tidy-tuesday/index.html#recent-projects",
    "href": "tidy-tuesday/index.html#recent-projects",
    "title": "Tidy Tuesday Analysis",
    "section": "",
    "text": "2024-01-02: Analysis on Global Temperature Changes\n2024-01-09: Analysis on Movie Ratings Trends\n2024-01-16: Analysis on World Population Growth\n\nFeel free to explore each analysis to see the data visualization, statistical methods, and insights drawn from each dataset."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "projects",
    "section": "",
    "text": "Logistic Regression for Predictive Modeling\n\n\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether a…\n\n\n\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/index.html#computational-epidemiology-models",
    "href": "projects/index.html#computational-epidemiology-models",
    "title": "Projects",
    "section": "",
    "text": "Developed agent-based models to simulate the spread of infectious diseases, incorporating real-world data to improve the accuracy of predictions.\nKey Technologies: R, Python, Geospatial Analysis"
  },
  {
    "objectID": "projects/index.html#oncology-data-analysis",
    "href": "projects/index.html#oncology-data-analysis",
    "title": "Projects",
    "section": "",
    "text": "Led data analysis efforts in oncology research, focusing on improving patient outcomes through data-driven insights.\nKey Technologies: SQL, Python, Machine Learning"
  },
  {
    "objectID": "projects/index.html#public-health-surveillance-systems",
    "href": "projects/index.html#public-health-surveillance-systems",
    "title": "Projects",
    "section": "",
    "text": "Designed and implemented public health surveillance systems to track and monitor the spread of non-communicable diseases.\nKey Technologies: R, SQL, Tableau"
  },
  {
    "objectID": "projects/index.html#bayesian-statistics-in-public-health",
    "href": "projects/index.html#bayesian-statistics-in-public-health",
    "title": "Projects",
    "section": "",
    "text": "Applied Bayesian statistical methods to public health research, contributing to more robust and reliable findings.\nKey Technologies: R, Bayesian Inference, Statistical Modeling"
  },
  {
    "objectID": "projects/index.html#reproducibility-in-research",
    "href": "projects/index.html#reproducibility-in-research",
    "title": "Projects",
    "section": "",
    "text": "Promoted best practices for reproducible research through workshops, publications, and the development of open-source tools.\nKey Technologies: R, Python, Git"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Nichodemus Amollo",
    "section": "",
    "text": "Kaggle\n  \n  \n    \n     Github\n  \n  \n    \n     Email\nI am a passionate data analyst and statistician specializing in computational epidemiology, public health, oncology research, and Bayesian statistics. With a strong background in data management, analysis, and storytelling, I am dedicated to using data to uncover insights that drive impactful decisions.. Over the past few years, I’ve become very interested in research software, open source, reproducibility and data science practices in public sector.\nIn my current role, I leverage my skills to contribute to cutting-edge research and projects that address critical public health challenges. My passion for data extends beyond the workplace, as I continually seek to expand my knowledge and share it through publications, speaking engagements, and mentoring.\nMy Key Research Interests are:\nI am currently pusruing my MSc in Epidemiology and Biostatistics at JOOUST, where I have finshed my coursework and designed a case study design to assess primary health facility financing for management of hypertension and diabestes in kisumu county. I look forward to registering for a PhD position to continue exploring the application of statistical methods in public health data, particularly in randomized clinical trails. Soon, I want to start developing R packages, I want to turn my thesis into a package, transparency, openness, and reproducibility."
  },
  {
    "objectID": "about/index.html#ongoing-publications",
    "href": "about/index.html#ongoing-publications",
    "title": "Nichodemus Amollo",
    "section": "Ongoing Publications",
    "text": "Ongoing Publications\n\n[assess primary health facility financing for management of hypertension and diabestes in kisumu county] - MSc Thesis.\n\nSometimes I teach biostatistics courses at JOOUST school of health sciences (JOOUST), Kisumu. As a DataCamp certified data scientist, I also teach and help with R programming at the LERIS HUB.\nI speak fluent English, Swahili and dholuo, and trying to learn French. Outside of work, I enjoy staying active and engaging in various sports. I have a deep appreciation for classical music, particularly Renaissance polyphony, and enjoy reading on topics ranging from Cold War history to Greek drama. Living with neuromyelitis optica has fueled my curiosity about complex health conditions and has driven me to understand them better through my research."
  },
  {
    "objectID": "blogs/index.html",
    "href": "blogs/index.html",
    "title": "Blogs",
    "section": "",
    "text": "Bayesian statistics offer a powerful framework for analyzing public health data. In this post, I explore its applications and benefits.\nRead more →\n\n\n\n\nReproducibility is crucial for advancing scientific knowledge. Here’s how we can improve reproducibility in epidemiological studies.\nRead more →\n\n\n\n\nAgent-based models provide a dynamic way to simulate the spread of infectious diseases. Learn how they work and why they’re important.\nRead more →\n\n\n\n\nExplore how data science is transforming oncology research, from early detection to personalized treatment.\nRead more →"
  },
  {
    "objectID": "blogs/index.html#latest-posts",
    "href": "blogs/index.html#latest-posts",
    "title": "Blogs",
    "section": "",
    "text": "Bayesian statistics offer a powerful framework for analyzing public health data. In this post, I explore its applications and benefits.\nRead more →\n\n\n\n\nReproducibility is crucial for advancing scientific knowledge. Here’s how we can improve reproducibility in epidemiological studies.\nRead more →\n\n\n\n\nAgent-based models provide a dynamic way to simulate the spread of infectious diseases. Learn how they work and why they’re important.\nRead more →\n\n\n\n\nExplore how data science is transforming oncology research, from early detection to personalized treatment.\nRead more →"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nichodemus Amollo",
    "section": "",
    "text": "Hello!\nI’m a data analyst and statistician passionate about public health data. I aim to use my expertise to drive impactful change, especially in resource-limited settings.\nWith over five years of experience, I’ve developed strong skills in data collection, analysis, and visualization. I’m proficient in RedCap and other EDC systems and have advanced expertise in R, SPSS, STATA, and SAS. My technical leadership and database management have been key in advancing public health projects.\nIn addition to my work, I serve as a part-time lecturer at JOOUST School of Health Sciences, where I teach statistics. I also conduct R programming workshops at LERIS HUB, helping researchers enhance their data analysis skills.\nOutside work, I’m a fitness enthusiast who enjoys morning runs and nature walks. I’ve been following a keto diet for two years and practice OMAD (One Meal A Day), integrating wellness into my daily routine."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "resources/index.html",
    "href": "resources/index.html",
    "title": "Resources",
    "section": "",
    "text": "Welcome to my resources page! Here, you’ll find a collection of tools, articles, and datasets that I regularly use in my work as a data analyst and statistician.\n\n\n\nR: A powerful tool for statistical computing and graphics.\nPython: Versatile programming language for data analysis, modeling, and visualization.\nSQL: Essential for managing and querying large datasets.\nTableau: Data visualization tool that helps turn data into actionable insights.\n\n\n\n\n\n“Bayesian Data Analysis” by Andrew Gelman\n“The Art of R Programming” by Norman Matloff\n“Deep Learning with Python” by François Chollet\n\n\n\n\n\nKaggle Datasets: A vast collection of datasets for various data science projects.\nWHO Health Data: Public health datasets from the World Health Organization.\nCDC WONDER: A comprehensive database of public health data."
  },
  {
    "objectID": "resources/index.html#data-science-tools",
    "href": "resources/index.html#data-science-tools",
    "title": "Resources",
    "section": "",
    "text": "R: A powerful tool for statistical computing and graphics.\nPython: Versatile programming language for data analysis, modeling, and visualization.\nSQL: Essential for managing and querying large datasets.\nTableau: Data visualization tool that helps turn data into actionable insights."
  },
  {
    "objectID": "resources/index.html#recommended-reading",
    "href": "resources/index.html#recommended-reading",
    "title": "Resources",
    "section": "",
    "text": "“Bayesian Data Analysis” by Andrew Gelman\n“The Art of R Programming” by Norman Matloff\n“Deep Learning with Python” by François Chollet"
  },
  {
    "objectID": "resources/index.html#useful-datasets",
    "href": "resources/index.html#useful-datasets",
    "title": "Resources",
    "section": "",
    "text": "Kaggle Datasets: A vast collection of datasets for various data science projects.\nWHO Health Data: Public health datasets from the World Health Organization.\nCDC WONDER: A comprehensive database of public health data."
  },
  {
    "objectID": "tidy-tuesday/2024-01-02-analysis.html",
    "href": "tidy-tuesday/2024-01-02-analysis.html",
    "title": "Global Temperature Changes",
    "section": "",
    "text": "This week’s Tidy Tuesday dataset focuses on global temperature changes over time. In this analysis, I explore the trends in global temperature increases and their potential implications on climate change.\n\n\n\n# Load necessary libraries\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'tibble' was built under R version 4.3.2\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.3.2\n\n\nWarning: package 'dplyr' was built under R version 4.3.2\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Generate random data\nset.seed(123)  # Set seed for reproducibility\n\n# Create a sequence of years from 1900 to 2024\nyears &lt;- seq(1900, 2024)\n\n# Generate random temperature changes, simulating a gradual increase over time\ntemperature_change &lt;- cumsum(rnorm(length(years), mean = 0.02, sd = 0.1))\n\n# Combine the years and temperature changes into a data frame\ntemperature_data &lt;- data.frame(year = years, temperature_change = temperature_change)\n\n# Preview the data\nhead(temperature_data)\n\n  year temperature_change\n1 1900        -0.03604756\n2 1901        -0.03906531\n3 1902         0.13680552\n4 1903         0.16385636\n5 1904         0.19678513\n6 1905         0.38829163\n\n\n\n# Example plot\nggplot(temperature_data, aes(x = year, y = temperature_change)) +\n  geom_line() +\n  labs(title = \"Global Temperature Changes Over Time\", x = \"Year\", y = \"Temperature Change (°C)\")"
  },
  {
    "objectID": "tidy-tuesday/2024-01-02-analysis.html#data-preparation",
    "href": "tidy-tuesday/2024-01-02-analysis.html#data-preparation",
    "title": "Global Temperature Changes",
    "section": "",
    "text": "# Load necessary libraries\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'tibble' was built under R version 4.3.2\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.3.2\n\n\nWarning: package 'dplyr' was built under R version 4.3.2\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Generate random data\nset.seed(123)  # Set seed for reproducibility\n\n# Create a sequence of years from 1900 to 2024\nyears &lt;- seq(1900, 2024)\n\n# Generate random temperature changes, simulating a gradual increase over time\ntemperature_change &lt;- cumsum(rnorm(length(years), mean = 0.02, sd = 0.1))\n\n# Combine the years and temperature changes into a data frame\ntemperature_data &lt;- data.frame(year = years, temperature_change = temperature_change)\n\n# Preview the data\nhead(temperature_data)\n\n  year temperature_change\n1 1900        -0.03604756\n2 1901        -0.03906531\n3 1902         0.13680552\n4 1903         0.16385636\n5 1904         0.19678513\n6 1905         0.38829163\n\n\n\n# Example plot\nggplot(temperature_data, aes(x = year, y = temperature_change)) +\n  geom_line() +\n  labs(title = \"Global Temperature Changes Over Time\", x = \"Year\", y = \"Temperature Change (°C)\")"
  },
  {
    "objectID": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html",
    "href": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html",
    "title": "Logistic Regression for Predictive Modeling",
    "section": "",
    "text": "This project uses a dataset from the National Institute of Diabetes and Digestive and Kidney Diseases to predict whether a patient has diabetes based on diagnostic measurements. The patients are female and of Pima Indian heritage, aged at least 21 years."
  },
  {
    "objectID": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#load-the-dataset",
    "href": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#load-the-dataset",
    "title": "Logistic Regression for Predictive Modeling",
    "section": "3.1 Load the Dataset",
    "text": "3.1 Load the Dataset\n\n\nCode\ndf &lt;- read.csv(\"diabetes.csv\")\n\n# Display the first few rows\ndf %&gt;% \n  head() %&gt;% \n  kable(caption = \"First Few Rows of the Diabetes Dataset\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, \n                position = \"left\")\n\n\n\n\nFirst Few Rows of the Diabetes Dataset\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n5\n116\n74\n0\n0\n25.6\n0.201\n30\n0"
  },
  {
    "objectID": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#summary-statistics",
    "href": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#summary-statistics",
    "title": "Logistic Regression for Predictive Modeling",
    "section": "3.2 Summary Statistics",
    "text": "3.2 Summary Statistics\n\n\nCode\n# Get summary statistics\nsummary_stats &lt;- summary(df)\nkable(summary_stats, caption = \"Summary Statistics of the Dataset\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n                full_width = F,\n                position = \"left\")\n\n\n\n\nSummary Statistics of the Dataset\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n\nMin. : 0.000\nMin. : 0.0\nMin. : 0.00\nMin. : 0.00\nMin. : 0.0\nMin. : 0.00\nMin. :0.0780\nMin. :21.00\nMin. :0.000\n\n\n\n1st Qu.: 1.000\n1st Qu.: 99.0\n1st Qu.: 62.00\n1st Qu.: 0.00\n1st Qu.: 0.0\n1st Qu.:27.30\n1st Qu.:0.2437\n1st Qu.:24.00\n1st Qu.:0.000\n\n\n\nMedian : 3.000\nMedian :117.0\nMedian : 72.00\nMedian :23.00\nMedian : 30.5\nMedian :32.00\nMedian :0.3725\nMedian :29.00\nMedian :0.000\n\n\n\nMean : 3.845\nMean :120.9\nMean : 69.11\nMean :20.54\nMean : 79.8\nMean :31.99\nMean :0.4719\nMean :33.24\nMean :0.349\n\n\n\n3rd Qu.: 6.000\n3rd Qu.:140.2\n3rd Qu.: 80.00\n3rd Qu.:32.00\n3rd Qu.:127.2\n3rd Qu.:36.60\n3rd Qu.:0.6262\n3rd Qu.:41.00\n3rd Qu.:1.000\n\n\n\nMax. :17.000\nMax. :199.0\nMax. :122.00\nMax. :99.00\nMax. :846.0\nMax. :67.10\nMax. :2.4200\nMax. :81.00\nMax. :1.000\n\n\n\n\n\n\n\n\n##3.3 Missing Values\n\n\nCode\n# Check for missing values\ncolSums(is.na(df))\n\n\n             Pregnancies                  Glucose            BloodPressure \n                       0                        0                        0 \n           SkinThickness                  Insulin                      BMI \n                       0                        0                        0 \nDiabetesPedigreeFunction                      Age                  Outcome \n                       0                        0                        0 \n\n\n#4. Exploratory Data Analysis (EDA) ##4.1 Univariate Analysis ###4.1.1 Distribution of Outcome Variable\n\n\nCode\n# Distribution of the Outcome variable\nggplot(df, aes(x=factor(Outcome))) +\n  geom_bar(fill=\"steelblue\") +\n  labs(x=\"Outcome\", y=\"Count\", title=\"Distribution of Diabetes Outcome\")\n\n\n\n\n\n\n\n\n\n###4.1.2 Distribution of Continuous Variables\n\n\nCode\n# Plot distributions of all continuous variables\ncontinuous_vars &lt;- df %&gt;% select(-Outcome, -Pregnancies)\ncontinuous_plots &lt;- lapply(names(continuous_vars), function(var) {\n  ggplot(df, aes_string(x=var)) +\n    geom_histogram(fill=\"steelblue\", bins=30) +\n    labs(x=var, y=\"Count\", title=paste(\"Distribution of\", var))\n})\n\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\nCode\ngrid.arrange(grobs=continuous_plots, ncol=2)"
  },
  {
    "objectID": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#bivariate-analysis",
    "href": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#bivariate-analysis",
    "title": "Logistic Regression for Predictive Modeling",
    "section": "4.2 Bivariate Analysis",
    "text": "4.2 Bivariate Analysis\n\n4.2.1 Correlation Matrix\n\n\nCode\n# Correlation matrix\ncorr_matrix &lt;- cor(df %&gt;% select(-Outcome))\nggcorr(corr_matrix, label=TRUE, label_size=3)"
  },
  {
    "objectID": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#relationships-with-outcome",
    "href": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#relationships-with-outcome",
    "title": "Logistic Regression for Predictive Modeling",
    "section": "4.2.2 Relationships with Outcome",
    "text": "4.2.2 Relationships with Outcome\n\n\nCode\n# Scatter plots for continuous variables vs Outcome\nscatter_plots &lt;- lapply(names(continuous_vars), function(var) {\n  ggplot(df, aes_string(x=var, y=\"Outcome\")) +\n    geom_point(alpha=0.5) +\n    labs(x=var, y=\"Outcome\", title=paste(var, \"vs Outcome\"))\n})\n\ngrid.arrange(grobs=scatter_plots, ncol=2)"
  },
  {
    "objectID": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#train-test-split",
    "href": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#train-test-split",
    "title": "Logistic Regression for Predictive Modeling",
    "section": "5.1.2 Train-Test Split",
    "text": "5.1.2 Train-Test Split\n\n\nCode\n# Create training (80%) and test (20%) sets\nset.seed(123)\ntrainIndex &lt;- createDataPartition(df_scaled$Outcome, p = .8, \n                                  list = FALSE, \n                                  times = 1)\ndfTrain &lt;- df_scaled[ trainIndex,]\ndfTest  &lt;- df_scaled[-trainIndex,]"
  },
  {
    "objectID": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#model-training",
    "href": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#model-training",
    "title": "Logistic Regression for Predictive Modeling",
    "section": "5.2 Model Training",
    "text": "5.2 Model Training\n\n\nCode\n# Fit logistic regression model\nlogit_model &lt;- glm(Outcome ~ ., data=dfTrain, family=binomial)\n\n# Summary of the model\nsummary(logit_model)\n\n\n\nCall:\nglm(formula = Outcome ~ ., family = binomial, data = dfTrain)\n\nCoefficients:\n                         Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              -1.31946    0.18002  -7.330 2.31e-13 ***\nPregnancies               0.11852    0.03579   3.311 0.000929 ***\nGlucose                   1.12827    0.13380   8.433  &lt; 2e-16 ***\nBloodPressure            -0.25320    0.11086  -2.284 0.022374 *  \nSkinThickness            -0.01560    0.12010  -0.130 0.896648    \nInsulin                  -0.10500    0.11341  -0.926 0.354533    \nBMI                       0.67938    0.13114   5.180 2.21e-07 ***\nDiabetesPedigreeFunction  0.25926    0.10642   2.436 0.014845 *  \nAge                       0.17927    0.12106   1.481 0.138676    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 797.28  on 614  degrees of freedom\nResidual deviance: 583.64  on 606  degrees of freedom\nAIC: 601.64\n\nNumber of Fisher Scoring iterations: 5"
  },
  {
    "objectID": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#model-evaluation",
    "href": "projects/my_projects/2024-08-24-diabetes/diabetes_eda_lr.html#model-evaluation",
    "title": "Logistic Regression for Predictive Modeling",
    "section": "5.3 Model Evaluation",
    "text": "5.3 Model Evaluation\n\n\nCode\n# Predict on test data\npred_probs &lt;- predict(logit_model, newdata=dfTest, type=\"response\")\npred_classes &lt;- ifelse(pred_probs &gt; 0.5, 1, 0)\n\n\n\n\nCode\n# Confusion matrix\nconf_matrix &lt;- confusionMatrix(factor(pred_classes), factor(dfTest$Outcome))\nconf_matrix\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 91 22\n         1 10 30\n                                          \n               Accuracy : 0.7908          \n                 95% CI : (0.7178, 0.8523)\n    No Information Rate : 0.6601          \n    P-Value [Acc &gt; NIR] : 0.0002786       \n                                          \n                  Kappa : 0.5063          \n                                          \n Mcnemar's Test P-Value : 0.0518299       \n                                          \n            Sensitivity : 0.9010          \n            Specificity : 0.5769          \n         Pos Pred Value : 0.8053          \n         Neg Pred Value : 0.7500          \n             Prevalence : 0.6601          \n         Detection Rate : 0.5948          \n   Detection Prevalence : 0.7386          \n      Balanced Accuracy : 0.7390          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\n\n\nCode\n# ROC curve and AUC\npred &lt;- prediction(pred_probs, dfTest$Outcome)\nperf &lt;- performance(pred, \"tpr\", \"fpr\")\nauc &lt;- performance(pred, \"auc\")@y.values[[1]]\n\n# Plot ROC curve\nplot(perf, col=\"blue\", lwd=2, main=paste(\"ROC Curve (AUC =\", round(auc, 2), \")\"))\nabline(a=0, b=1, lty=2, col=\"red\")\n\n\n\n\n\n\n\n\n\n\nSteps to Use This Template:\n\nSave the .qmd file: Copy the content above into a text editor and save it as diabetes_analysis.qmd.\nPlace the dataset: Ensure the diabetes.csv file is in your working directory.\nRender the Quarto document: Open the .qmd file in an R or Quarto-compatible IDE (such as RStudio) and render it to create the report.\n\nThis template includes loading necessary packages without warnings, performing EDA with visualizations, and running a logistic regression analysis."
  }
]